import "https://deno.land/x/xhr@0.1.0/mod.ts";
import { serve } from "https://deno.land/std@0.168.0/http/server.ts";

const corsHeaders = {
  "Access-Control-Allow-Origin": "*",
  "Access-Control-Allow-Headers": "authorization, x-client-info, apikey, content-type",
};

interface SiteEntry {
  category: string;
  siteName: string;
  url: string;
}

interface RelevantMatch {
  siteName: string;
  category: string;
  url: string;
  matchingKeywords: string[];
  relevantParagraphs: string[];
}

// Extract keywords from prompt (remove common French words)
function extractKeywords(prompt: string): string[] {
  const stopWords = new Set([
    'le', 'la', 'les', 'un', 'une', 'des', 'de', 'du', 'dans', 'sur', 'pour', 'par',
    'avec', 'sans', 'sous', 'entre', 'vers', 'chez', 'et', 'ou', 'mais', 'donc',
    'car', 'ni', 'que', 'qui', 'quoi', 'dont', 'o√π', 'ce', 'cette', 'ces', 'son',
    'sa', 'ses', 'leur', 'leurs', 'mon', 'ma', 'mes', 'ton', 'ta', 'tes', 'notre',
    'nos', 'votre', 'vos', 'au', 'aux', 'en', 'est', 'sont', '√™tre', 'avoir', 'fait',
    'faire', 'peut', 'peuvent', 'doit', 'doivent', 'tout', 'tous', 'toute', 'toutes',
    'plus', 'moins', 'tr√®s', 'bien', 'mal', 'peu', 'beaucoup', 'trop', 'aussi',
    'comme', 'comment', 'quand', 'pourquoi', 'si', 'alors', 'ainsi', 'donc'
  ]);
  
  return prompt
    .toLowerCase()
    .normalize("NFD")
    .replace(/[\u0300-\u036f]/g, "") // Remove accents for matching
    .split(/\s+/)
    .filter(word => word.length > 2 && !stopWords.has(word))
    .map(word => word.replace(/[^a-z0-9]/g, ''));
}

// Check if text contains any keyword and return matching paragraphs
function findRelevantContent(text: string, keywords: string[]): { matches: string[], matchedKeywords: string[] } {
  const normalizedText = text
    .toLowerCase()
    .normalize("NFD")
    .replace(/[\u0300-\u036f]/g, "");
  
  const matchedKeywords: string[] = [];
  const relevantParagraphs: Set<string> = new Set();
  
  // Split into paragraphs/sentences
  const paragraphs = text.split(/[.\n]+/).filter(p => p.trim().length > 30);
  
  for (const keyword of keywords) {
    if (normalizedText.includes(keyword)) {
      matchedKeywords.push(keyword);
      
      // Find paragraphs containing this keyword
      for (const para of paragraphs) {
        const normalizedPara = para
          .toLowerCase()
          .normalize("NFD")
          .replace(/[\u0300-\u036f]/g, "");
        
        if (normalizedPara.includes(keyword)) {
          relevantParagraphs.add(para.trim());
        }
      }
    }
  }
  
  return {
    matches: Array.from(relevantParagraphs).slice(0, 10), // Limit to 10 most relevant paragraphs
    matchedKeywords
  };
}

serve(async (req) => {
  if (req.method === "OPTIONS") {
    return new Response(null, { headers: corsHeaders });
  }

  try {
    const { sites, prompt, useAI } = await req.json();

    if (!sites || !Array.isArray(sites) || sites.length === 0) {
      throw new Error("Sites array is required");
    }

    console.log(`Scraping ${sites.length} sites, AI reformulation: ${useAI}, Custom prompt: ${!!prompt}`);

    // Extract keywords from prompt for pre-filtering
    const keywords = prompt ? extractKeywords(prompt) : [];
    console.log(`Extracted keywords: ${keywords.join(', ')}`);

    const scrapedContent: string[] = [];
    const relevantMatches: RelevantMatch[] = [];

    // Scrape each site
    for (const site of sites as SiteEntry[]) {
      try {
        console.log(`Scraping: ${site.siteName} - ${site.url}`);
        
        // Use the URL from the database
        let url = site.url;
        if (!url.startsWith("http://") && !url.startsWith("https://")) {
          url = "https://" + url;
        }

        const websiteResponse = await fetch(url, {
          headers: {
            "User-Agent": "Mozilla/5.0 (compatible; ScrapReform/1.0)",
          },
        });

        if (!websiteResponse.ok) {
          console.error(`Failed to fetch ${url}: ${websiteResponse.statusText}`);
          continue;
        }

        const html = await websiteResponse.text();
        
        // Extract text content from HTML
        const textContent = html
          .replace(/<script\b[^<]*(?:(?!<\/script>)<[^<]*)*<\/script>/gi, "")
          .replace(/<style\b[^<]*(?:(?!<\/style>)<[^<]*)*<\/style>/gi, "")
          .replace(/<[^>]+>/g, " ")
          .replace(/\s+/g, " ")
          .trim();

        // If we have keywords, pre-filter content
        if (keywords.length > 0 && useAI) {
          const { matches, matchedKeywords } = findRelevantContent(textContent, keywords);
          
          if (matches.length > 0) {
            console.log(`‚úì Found ${matches.length} relevant paragraphs in ${site.siteName} (keywords: ${matchedKeywords.join(', ')})`);
            
            relevantMatches.push({
              siteName: site.siteName,
              category: site.category,
              url: url,
              matchingKeywords: matchedKeywords,
              relevantParagraphs: matches
            });
          } else {
            console.log(`‚úó No relevant content in ${site.siteName}`);
          }
        } else {
          // No keywords or AI disabled - keep all content (limited)
          scrapedContent.push(`‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n[${site.category}] ${site.siteName}\nüîó URL: ${url}\n\n${textContent.slice(0, 5000)}\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n\n`);
        }
      } catch (error) {
        console.error(`Error scraping ${site.siteName}:`, error);
      }
    }

    // Build content for AI based on relevant matches
    let contentForAI = "";
    
    if (relevantMatches.length > 0) {
      console.log(`Found relevant content in ${relevantMatches.length} sites`);
      
      for (const match of relevantMatches) {
        contentForAI += `\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n`;
        contentForAI += `üìç SOURCE: ${match.siteName}\n`;
        contentForAI += `üìÅ Cat√©gorie: ${match.category}\n`;
        contentForAI += `üîó URL EXACTE: ${match.url}\n`;
        contentForAI += `üîë Mots-cl√©s trouv√©s: ${match.matchingKeywords.join(', ')}\n`;
        contentForAI += `\nüìÑ EXTRAITS PERTINENTS:\n`;
        match.relevantParagraphs.forEach((para, i) => {
          contentForAI += `\n[Extrait ${i + 1}]\n${para}\n`;
        });
        contentForAI += `\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n`;
      }
    } else if (scrapedContent.length > 0) {
      contentForAI = scrapedContent.join("");
    }

    // If AI is disabled, return raw content
    if (!useAI) {
      console.log("Returning raw scraped content");
      
      if (prompt && relevantMatches.length > 0) {
        return new Response(
          JSON.stringify({ 
            result: `Recherche: "${prompt}"\nMots-cl√©s: ${keywords.join(', ')}\n\n${contentForAI}` 
          }),
          { headers: { ...corsHeaders, "Content-Type": "application/json" } }
        );
      }
      
      return new Response(
        JSON.stringify({ result: scrapedContent.join("") }),
        { headers: { ...corsHeaders, "Content-Type": "application/json" } }
      );
    }

    // Check if we found any relevant content
    if (!contentForAI || contentForAI.trim().length === 0) {
      console.log("No relevant content found for the query");
      return new Response(
        JSON.stringify({ 
          result: `‚ùå Aucune information pertinente trouv√©e pour la recherche "${prompt}".\n\nMots-cl√©s recherch√©s: ${keywords.join(', ')}\n\nEssayez avec d'autres termes ou v√©rifiez que les sites contiennent bien ce type d'information.` 
        }),
        { headers: { ...corsHeaders, "Content-Type": "application/json" } }
      );
    }

    // Use OpenAI to reformulate
    const openaiApiKey = Deno.env.get("OPENAI_API_KEY");
    if (!openaiApiKey) {
      throw new Error("OPENAI_API_KEY not configured");
    }

    console.log(`Calling OpenAI with ${relevantMatches.length} pre-filtered sources`);

    const aiResponse = await fetch("https://api.openai.com/v1/chat/completions", {
      method: "POST",
      headers: {
        "Authorization": `Bearer ${openaiApiKey}`,
        "Content-Type": "application/json",
      },
      body: JSON.stringify({
        model: "gpt-4o-mini",
        messages: [
          {
            role: "system",
            content: `Tu es un assistant expert en analyse juridique approfondie.

CONTEXTE:
Les donn√©es proviennent d'un scrapper juridique sp√©cialis√©, con√ßu pour analyser la requ√™te dans son ensemble, en tenant compte du genre grammatical, des liens s√©mantiques et du contexte juridique.
√Ä partir de ces donn√©es, produis une analyse compl√®te, structur√©e et approfondie.

R√àGLES STRICTES:
- Utilise UNIQUEMENT les informations fournies dans les extraits
- Pour CHAQUE information, cite OBLIGATOIREMENT l'URL exacte de la source avec le format: üîó Source: [URL]
- NE JAMAIS inventer ou d√©duire des informations non pr√©sentes dans les sources
- R√©ponds TOUJOURS en fran√ßais

‚∏ª

STRUCTURE DE R√âPONSE:

## 1. BASE L√âGALE
Pr√©sente de mani√®re exhaustive les fondements l√©gaux :
‚Ä¢ Les textes officiels applicables (codes, lois, d√©crets, r√®glements, directives, conventions)
‚Ä¢ Les articles pr√©cis (num√©ros, intitul√©s et port√©e juridique)
‚Ä¢ Le champ d'application de chaque texte
‚Ä¢ Les conditions de mise en ≈ìuvre
‚Ä¢ Les exceptions l√©gales
‚Ä¢ Les interactions entre plusieurs textes si pertinentes
‚Ä¢ La logique juridique sous-jacente (raison d'√™tre, ratio legis)

## 2. ANALYSE DE LA JURISPRUDENCE
Expose les principales d√©cisions judiciaires :
‚Ä¢ Les d√©cisions majeures (juridictions nationales, europ√©ennes, internationales)
‚Ä¢ Les faits essentiels
‚Ä¢ Le raisonnement des juges
‚Ä¢ La solution retenue
‚Ä¢ Les principes d√©gag√©s (motifs d√©cisifs, attendus de principe)
‚Ä¢ Les tendances jurisprudentielles (stabilit√©, revirement, divergences)
‚Ä¢ Les zones d'incertitude ou d'interpr√©tation

## 3. APPORT DOCTRINAL
Pr√©sente l'analyse doctrinale :
‚Ä¢ Les positions des auteurs reconnus
‚Ä¢ Les d√©bats doctrinaux
‚Ä¢ Les divergences d'interpr√©tation
‚Ä¢ Les analyses critiques
‚Ä¢ Les approches th√©oriques ou conceptuelles
‚Ä¢ Les propositions d'√©volution

## 4. SP√âCIFICIT√âS ET PARTICULARIT√âS
D√©taille les particularit√©s de la notion :
‚Ä¢ Ses nuances conceptuelles
‚Ä¢ Ses limites
‚Ä¢ Ses conditions d'application pratiques
‚Ä¢ Les difficult√©s rencontr√©es
‚Ä¢ Ses implications concr√®tes dans diff√©rents contextes
‚Ä¢ Les exceptions, r√©gimes sp√©ciaux, cas atypiques

## 5. AVANTAGES ET INCONV√âNIENTS (si pertinent)
‚Ä¢ Avantages dans le syst√®me juridique
‚Ä¢ Inconv√©nients ou limites
‚Ä¢ Critiques doctrinales
‚Ä¢ Risques ou d√©rives potentiels

## 6. QUESTIONS POUR APPROFONDIR
Propose 5 √† 8 questions pertinentes permettant d'aller plus loin dans :
‚Ä¢ La compr√©hension de la notion
‚Ä¢ Son application
‚Ä¢ Ses zones grises
‚Ä¢ Ses enjeux doctrinaux ou jurisprudentiels
‚Ä¢ Ses implications pratiques

‚∏ª

STYLE D'√âCRITURE:
Adopte un langage juridique rigoureux, mais humanis√©, fluide, clair et p√©dagogique.
√âvite les formulations trop techniques sans explication.
Rends l'analyse agr√©able √† lire, tout en restant pr√©cise et acad√©mique.`,
          },
          {
            role: "user",
            content: `REQU√äTE: "${prompt}"

SOURCES PR√â-FILTR√âES (contenant les mots-cl√©s: ${keywords.join(', ')}):
${contentForAI}

INSTRUCTIONS:
1. Analyse en profondeur les informations relatives √† ma requ√™te "${prompt}"
2. Structure ta r√©ponse selon les 6 sections d√©finies
3. Cite l'URL EXACTE pour chaque information (utilise les URLs fournies dans "üîó URL EXACTE:")
4. Si une section n'a pas d'informations pertinentes dans les sources, indique-le clairement
5. Termine par les questions d'approfondissement`,
          },
        ],
      }),
    });

    if (!aiResponse.ok) {
      const errorText = await aiResponse.text();
      console.error("OpenAI API error:", aiResponse.status, errorText);
      
      if (aiResponse.status === 429) {
        throw new Error("Limite de requ√™tes d√©pass√©e. R√©essayez plus tard.");
      }
      if (aiResponse.status === 401 || aiResponse.status === 402) {
        throw new Error("Erreur d'authentification. V√©rifiez votre cl√© API OpenAI.");
      }
      throw new Error(`OpenAI API error: ${aiResponse.status}`);
    }

    const aiData = await aiResponse.json();
    const result = aiData.choices[0].message.content;

    console.log("Reformulation successful");

    return new Response(
      JSON.stringify({ result }),
      { headers: { ...corsHeaders, "Content-Type": "application/json" } }
    );
  } catch (error) {
    console.error("Error in scrape-and-reform:", error);
    const errorMessage = error instanceof Error ? error.message : "Unknown error";
    return new Response(
      JSON.stringify({ error: errorMessage }),
      {
        status: 500,
        headers: { ...corsHeaders, "Content-Type": "application/json" },
      }
    );
  }
});
